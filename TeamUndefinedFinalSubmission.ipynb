{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4320 Introduction to Machine Learning\n",
    "\n",
    "## Team Undefined\n",
    "\n",
    "### Group Members: \n",
    "\n",
    "- Luke Shumway A02268065\n",
    "\n",
    "- Ryan Andersen A02288683\n",
    "\n",
    "- Ian Adams A02252812\n",
    "\n",
    "Project: [Store Sales - Time Series Forecasting](https://www.kaggle.com/competitions/store-sales-time-series-forecasting/overview/description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroupName = \"Undefined\"\n",
    "assert GroupName != \"\", 'Please enter your name in the above quotation marks, thanks!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "0. [Submission instructions](#si)\n",
    "1. [Understanding the problem](#1)\n",
    "2. [Exploratory Data Analysis](#2)\n",
    "3. [Data aggregation, Splitting, and Feature Engineering](#3)\n",
    "4. [Preprocessing and transformations](#4)\n",
    "5. [Baseline model](#5) \n",
    "6. [Linear models](#6)\n",
    "7. [Different models](#7)\n",
    "8. [Feature selection](#8)\n",
    "9. [Hyperparameter optimization](#9)\n",
    "10. [Interpretation and feature importances](#10)\n",
    "11. [Results on the test set](#11) \n",
    "12. [Submit the predictions to Kaggle](#12)\n",
    "13. [Your takeaway from the course](#13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions <a name=\"si\"></a>\n",
    "<hr>\n",
    "\n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- Upload the .ipynb file to Canvas.\n",
    "- **Submit the screenshot of your Kaggle submission ranking and score** \n",
    "- Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`.\n",
    "- Notebooks with cell execution numbers out of order will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "- Make sure that the plots and output are rendered properly in your submitted file. \n",
    "- Please keep your notebook clean and delete any throwaway code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"in\"></a>\n",
    "\n",
    "A few notes and tips when you work on this project: \n",
    "\n",
    "#### Tips\n",
    "1. The project is open-ended, and while working on it, there might be some situations where you'll have to use your own judgment and make your own decisions (as you would be doing when you work as a data scientist). Make sure you explain your decisions whenever necessary. \n",
    "2. **Do not include everything you ever tried in your submission** -- it's fine just to have your final code. That said, your code should be reproducible and well-documented. For example, if you chose your hyperparameters based on some hyperparameter optimization experiment, you should leave in the code for that experiment so that someone else could re-run it and obtain the same hyperparameters, rather than mysteriously just setting the hyperparameters to some (carefully chosen) values in your code. \n",
    "3. If you realize that you are repeating a lot of code try to organize it in functions. Clear presentation of your code, experiments, and results is the key to be successful in this lab. You may use code from lecture notes or previous lab solutions with appropriate attributions. \n",
    "\n",
    "#### Assessment\n",
    "We plan to grade fairly and leniently. We don't have some secret target score that you need to achieve to get a good grade. **You'll be assessed on demonstration of mastery of course topics, clear presentation, and the quality of your analysis and results.** For example, if you just have a bunch of code and no text or figures, that's not good. If you do a bunch of sane things and get a lower accuracy than your friend, don't sweat it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 1. Pick your problem and explain the prediction problem <a name=\"1\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Spend some time understanding the problem and what each feature means. Write a few sentences on your initial thoughts on the problem and the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is a template for all submissions\n",
    "sample_df = pd.read_csv('file:sample_submission.csv')\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 2. Exploratory Data Analysis <a name=\"2\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Perform exploratory data analysis on the train set.\n",
    "2. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n",
    "3. Summarize your initial observations about the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't display this one, because we don't want to look at the testing data\n",
    "test_df = pd.read_csv('file:test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('file:train.csv')\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_df = pd.read_csv('file:oil.csv')\n",
    "display(oil_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_df = pd.read_csv('file:holidays_events.csv')\n",
    "display(holiday_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df = pd.read_csv('file:stores.csv')\n",
    "display(stores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv('file:transactions.csv')\n",
    "display(transactions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_df['locale_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df['state'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 3. Data aggregation, splitting, and feature engineering <a name=\"3\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train and test portions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineers more features based off the date\n",
    "def create_date_features(df):\n",
    "    df['month'] = pd.to_datetime(df.date, format='%Y-%m-%d').dt.month\n",
    "    df['day_of_month'] = pd.to_datetime(df.date, format='%Y-%m-%d').dt.day\n",
    "    df['day_of_year'] = pd.to_datetime(df.date, format='%Y-%m-%d').dt.dayofyear\n",
    "    df['day_of_week'] = pd.to_datetime(df.date, format='%Y-%m-%d').dt.dayofweek\n",
    "    df['year'] = pd.to_datetime(df.date, format='%Y-%m-%d').dt.year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in the testing or training set and merges data from the other tables with it\n",
    "# Also integrates feature engineering\n",
    "# Note: Data was already split into initial training and testing sets\n",
    "def merge_data(in_df):\n",
    "    t_oil_df = pd.merge(in_df, oil_df, how=\"left\", on=\"date\")\n",
    "    t_holiday_df = pd.merge(t_oil_df, holiday_df, how=\"left\", on=\"date\")\n",
    "    t_transact_df = pd.merge(t_holiday_df, transactions_df, how=\"left\", on=[\"date\", \"store_nbr\"])\n",
    "    full_df = pd.merge(t_transact_df, stores_df, how=\"left\", on=\"store_nbr\")\n",
    "    full_df.rename(columns={\"type_x\":\"holiday_type\", \"type_y\":\"store_type\", \"dcoilwtico\":\"oil_price\"}, inplace = True)\n",
    "    return create_date_features(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_df = merge_data(train_df)\n",
    "full_test_df = merge_data(test_df)\n",
    "\n",
    "X_train = full_train_df.drop(columns=[\"sales\"])\n",
    "y_train = full_train_df[\"sales\"]\n",
    "\n",
    "X_test = full_train_df.drop(columns=[\"sales\"])\n",
    "y_test = full_train_df[\"sales\"]\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 4. Preprocessing and transformations <a name=\"4\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Identify different feature types and the transformations you would apply on each feature type. \n",
    "2. Define a column transformer, if necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"store_nbr\", \"onpromotion\", \"oil_price\", \"cluster\", \"transactions\", \"month\", \"day_of_month\", \"day_of_year\", \"day_of_week\", \"year\"] \n",
    "categorical_features = [\"family\", \"holiday_type\", \"locale\", \"locale_name\", \"city\", \"state\", \"store_type\"]\n",
    "drop_features = [\"transferred\", \"id\"]  # do not include these features in modeling\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (make_pipeline(SimpleImputer(strategy='median'), StandardScaler()), numeric_features),\n",
    "    (make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder(handle_unknown=\"ignore\")), categorical_features))\n",
    "    ('drop', drop_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 5. Baseline model <a name=\"5\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try `scikit-learn`'s baseline model and report results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummyPipe = make_pipeline(preprocessor, DummyRegressor(strategy=\"median\"))\n",
    "results_dict['DummyRegressor'] = mean_std_cross_val_scores(dummyPipe, X_train, y_train, cv=3, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 6. Linear models <a name=\"6\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try a linear model as a first real attempt. \n",
    "2. Carry out hyperparameter tuning to explore different values for the complexity hyperparameter. \n",
    "3. Report cross-validation scores along with standard deviation. \n",
    "4. Summarize your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrPipe = make_pipeline(preprocessor, LinearRegression(n_jobs=-1))\n",
    "results_dict['LinearRegressor'] = mean_std_cross_val_scores(lrPipe, X_train, y_train, cv=3, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 7. Different models <a name=\"7\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try other models aside from a linear model. One of these models should be a tree-based ensemble model. \n",
    "2. Summarize your results in terms of overfitting/underfitting and fit and score times. Can you beat a linear model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtPipe = make_pipeline(preprocessor, DecisionTreeRegressor(max_depth=10))\n",
    "results_dict['DecisionTreeRegressor'] = mean_std_cross_val_scores(dtPipe, X_train, y_train, cv=3, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgrPipe = make_pipeline(preprocessor, LogisticRegression(n_jobs=-1))\n",
    "results_dict['LogisticRegressor'] = mean_std_cross_val_scores(dtPipe, X_train, y_train, cv=3, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmPipe = make_pipeline(preprocessor, 'insert model') # add model\n",
    "results_dict['LightGBM'] = mean_std_cross_val_scores(lgbmPipe, X_train, y_train, cv=3, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbPipe = make_pipeline(preprocessor, XGBRegressor(objective='reg:squaredlogerror'))\n",
    "results_dict['XGBoost'] = mean_std_cross_val_scores(xgbPipe, X_train, y_train, cv=3, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catPipe = make_pipeline(preprocessor, 'insert model') # add model\n",
    "results_dict['CatBoost'] = mean_std_cross_val_scores(catPipe, X_train, y_train, cv=3, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 8. Feature selection <a name=\"8\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to select relevant features. Do the results improve with feature selection? Summarize your results. If you see improvements in the results, keep feature selection in your pipeline. If not, you may abandon it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 9. Hyperparameter optimization <a name=\"9\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. In at least one case you should be optimizing multiple hyperparameters for a single model. You may use `sklearn`'s methods for hyperparameter optimization or fancier Bayesian optimization methods. \n",
    "  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n",
    "  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_dict = {\n",
    "    \"xgbregressor__booster\": ['gbtree', 'gblinear'],\n",
    "    \"xgbregressor__n_estimators\": [50, 100, 150, 200, 250, 300, 350],\n",
    "    \"xgbregressor__max_depth\": [3, 4, 5, 6, 7, 8],\n",
    "    \"xgbregressor__max_delta_step\": [2, 3, 4, 5, 6, 7],\n",
    "    \"xgbregressor__gamma\": [.01, .1],\n",
    "    \"xgbregressor__learning_rate\": [.01, .05, .1, .15, .2, .25, .3],\n",
    "    \"xgbregressor__grow_policy\": ['depthwise', 'lossguide'],\n",
    "    \"xgbregressor__tree_method\": ['exact', 'hist', 'approx'],\n",
    "}\n",
    "\n",
    "xgb_op_pipe = make_pipeline(preprocessor, XGBRegressor(objective='reg:squaredlogerror'))\n",
    "\n",
    "xgb_r_search = RandomizedSearchCV(xgb_op_pipe, param_dict, cv=5, n_jobs=-1, scoring=\"f1\", random_state=123, return_train_score=True)\n",
    "xgb_r_search.fit(X_train, y_train)\n",
    "\n",
    "print(xgb_r_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipe_best = make_pipeline(\n",
    "    preprocessor,\n",
    "    XGBRegressor(\n",
    "        n_estimators=xgb_r_search.best_params_['xgbregressor__n_estimators'],\n",
    "        max_depth=xgb_r_search.best_params_['xgbregressor__max_depth'],\n",
    "        objective='reg:squaredlogerror',\n",
    "        booster=xgb_r_search.best_params_['xgbregressor__booster'],\n",
    "        max_delta_step=xgb_r_search.best_params_['xgbregressor__max_delta_step'],\n",
    "        gamma=xgb_r_search.best_params_['xgbregressor__gamma'],\n",
    "        learning_rate=xgb_r_search.best_params_['xgbregressor__learning_rate'],\n",
    "        grow_policy=xgb_r_search.best_params_['xgbregressor__grow_policy'],\n",
    "        tree_method=xgb_r_search.best_params_['xgbregressor__tree_method'],\n",
    "    )\n",
    ")\n",
    "xgb_pipe_best.fit(X_train, y_train)\n",
    "results_dict['Optimized XGBoost'] = mean_std_cross_val_scores(xgb_pipe_best, X_train, y_train, cv=3, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 10. Interpretation and feature importances <a name=\"10\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Use the methods we saw in class (e.g., `eli5`, `shap`) (or any other methods of your choice) to examine the most important features of one of the non-linear models. \n",
    "2. Summarize your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 11. Results on the test set <a name=\"11\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try your best performing model on the test data (from train test split) and report test scores. \n",
    "2. Do the test scores agree with the validation scores from before? To what extent do you trust your results? Do you think you've had issues with optimization bias? \n",
    "3. Take one or two test predictions and explain these individual predictions (e.g., with SHAP force plots).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 12. Submit the predictions to Kaggle <a name=\"12\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Retrain the best model on the whole training dataset and upload the predicted output on the test set to Kaggle. Report your final test score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 13. Your takeaway <a name=\"13\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "What is your biggest takeaway from the supervised machine learning material we have learned so far? Please write thoughtful answers.  Discuss other ideas that you did not try but could potentially improve the performance/interpretability . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
